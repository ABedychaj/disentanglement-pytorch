{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from math import gamma\n",
    "\n",
    "def random_choice_full(input, n_samples, number_of_gausses):\n",
    "        from torch import multinomial, ones\n",
    "        if n_samples * number_of_gausses < input.shape[0]:\n",
    "            replacement = False\n",
    "        else:\n",
    "            replacement = True\n",
    "        idx = multinomial(ones(input.shape[0]), n_samples * number_of_gausses, replacement=replacement)\n",
    "        sampled = input[idx].reshape(number_of_gausses, n_samples, -1)\n",
    "        return torch.mean(sampled, axis=1)\n",
    "\n",
    "def provide_weights_for_x(x, how = None, device = None):\n",
    "    dim = x.shape[1]\n",
    "    scale = (1 / dim)\n",
    "\n",
    "    if how == \"gauss\":\n",
    "        from torch.distributions import MultivariateNormal\n",
    "        \n",
    "        sampled_points = random_choice_full(x, dim, dim)\n",
    "        cov_mat = (scale * torch.eye(dim)).repeat(dim, 1, 1)\n",
    "        mvn = MultivariateNormal(loc=sampled_points.to(device), covariance_matrix=cov_mat.to(device))\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "        \n",
    "    elif how == \"sqrt\":\n",
    "        weight_vector = 1 / torch.sqrt(1 + x.reshape(-1, 1, dim).to(device)**2)\n",
    "        \n",
    "    elif how == \"log\":\n",
    "        weight_vector = torch.log(1 + x.reshape(-1, 1, dim).to(device)**2)\n",
    "        \n",
    "    elif how == \"TStudent\":\n",
    "        from torch.distributions.studentT import StudentT\n",
    "        \n",
    "        mvn = StudentT(df=1, loc=x.mean(0), scale=scale)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "        # to trzeba poprawiÄ‡ ?!\n",
    "    elif how == \"Cauchy\":\n",
    "        from torch.distributions.cauchy import Cauchy\n",
    "        \n",
    "        mvn = Cauchy(loc=x.mean(0), scale=1)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "    elif how == \"Gumbel\":\n",
    "        from torch.distributions.gumbel import Gumbel\n",
    "        \n",
    "        mvn = Gumbel(loc=x.mean(0), scale=1)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "    elif how == \"Laplace\":\n",
    "        from torch.distributions.laplace import Laplace\n",
    "        \n",
    "        mvn = Laplace(loc=x.mean(0), scale=1)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "    return weight_vector\n",
    "    \n",
    "class WICA(object):\n",
    "    def __init__(self):\n",
    "        self.number_of_gausses = 5\n",
    "        self.z_dim = 5\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def wica_loss(self, z, latent_normalization=False, how=\"gauss\"):\n",
    "        if latent_normalization:\n",
    "            x = (z - z.mean(dim=1, keepdim=True)) / z.std(dim=1, keepdim=True)\n",
    "        else:\n",
    "            x = z\n",
    "        dim = self.z_dim if self.z_dim is not None else x.shape[1]\n",
    "\n",
    "\n",
    "        weight_vector = provide_weights_for_x(\n",
    "                x=x, \n",
    "                how=how,\n",
    "                device = self.device\n",
    "        )\n",
    "                \n",
    "        print(weight_vector.shape)\n",
    "        \n",
    "        sum_of_weights = torch.sum(weight_vector, axis=0)\n",
    "        weight_sum = torch.sum(x * weight_vector.T.reshape(self.number_of_gausses, -1, 1), axis=1)\n",
    "        weight_mean = weight_sum / sum_of_weights.reshape(-1, 1)\n",
    "\n",
    "        xm = x - weight_mean.reshape(self.number_of_gausses, 1, -1)\n",
    "        wxm = xm * weight_vector.T.reshape(self.number_of_gausses, -1, 1)\n",
    "\n",
    "        wcov = (wxm.permute(0, 2, 1).matmul(xm)) / sum_of_weights.reshape(-1, 1, 1)\n",
    "\n",
    "        diag = torch.diagonal(wcov ** 2, dim1=1, dim2=2)\n",
    "        diag_pow_plus = diag.reshape(diag.shape[0], diag.shape[1], -1) + diag.reshape(diag.shape[0], -1, diag.shape[1])\n",
    "\n",
    "        tmp = (2 * wcov ** 2 / diag_pow_plus)\n",
    "\n",
    "        triu = torch.triu(tmp, diagonal=1)\n",
    "        normalize = 2.0 / (dim * (dim - 1))\n",
    "        cost = torch.sum(normalize * triu) / self.number_of_gausses\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "wica = WICA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0815, -0.1086,  0.2232, -0.0168, -0.0041])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.sin(torch.randn(100)).resize(20,5)\n",
    "t.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.0530)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(wica.wica_loss(t, latent_normalization=False, how=\"TStudent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n",
      "torch.Size([20, 1, 5])\n",
      "tensor(0.1065)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(wica.wica_loss(t, latent_normalization=True, how=\"sqrt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '/Users/andrzej/Personal/Projects/disentanglement-pytorch')\n",
    "from models.vae import VAEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAEModel(\n",
       "  (encoder): SimpleGaussianConv64(\n",
       "    (main): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Flatten3D()\n",
       "      (13): Linear(in_features=256, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): SimpleConv64(\n",
       "    (main): Sequential(\n",
       "      (0): Unsqueeze3D()\n",
       "      (1): Conv2d(8, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (10): ReLU(inplace=True)\n",
       "      (11): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architectures import encoders, decoders\n",
    "\n",
    "encoder_name = \"SimpleGaussianConv64\"\n",
    "decoder_name = \"SimpleConv64\"\n",
    "\n",
    "encoder = getattr(encoders, encoder_name)\n",
    "decoder = getattr(decoders, decoder_name)\n",
    "\n",
    "model = VAEModel(encoder(8, 1, 64), decoder(8, 1, 64)).to(torch.device('cpu'))\n",
    "\n",
    "checkpoint = torch.load('/Users/andrzej/Personal/results/multiple-wicas/last', map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(checkpoint['model_states']['G'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_loader import get_dataloader\n",
    "\n",
    "train_loader = get_dataloader('dsprites_full', '/Users/andrzej/Personal/Projects/data/test_dsets', 3,\n",
    "                              123, num_workers=1, pin_memory=True, image_size=64, \n",
    "                              include_labels=None, shuffle=True, droplast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils\n",
    "def visualize_recon(input_image, recon_image):\n",
    "        input_image = torchvision.utils.make_grid(input_image)\n",
    "        recon_image = torchvision.utils.make_grid(recon_image)\n",
    "\n",
    "        white_line = torch.ones((3, input_image.size(1), 10)).to('cpu')\n",
    "        samples = torch.cat([input_image, white_line, recon_image], dim=2)\n",
    "\n",
    "        torchvision.utils.save_image(samples, \"test.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_recon(x,model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.utils import grid2gif, get_data_for_visualization, prepare_data_for_visualization\n",
    "import os\n",
    "\n",
    "z_dim = 8\n",
    "l_dim = 0\n",
    "traverse_z = True\n",
    "traverse_c = False\n",
    "num_labels = 0\n",
    "image_size = 64\n",
    "num_channels = train_loader.dataset.num_channels()\n",
    "\n",
    "def set_z(z, latent_id, val):\n",
    "    z[:, latent_id] = val\n",
    "\n",
    "def encode_deterministic(**kwargs):\n",
    "    images = kwargs['images']\n",
    "    if len(images.size()) == 3:\n",
    "        images = images.unsqueeze(0)\n",
    "    return model.encode(images)\n",
    "\n",
    "def decode_deterministic(**kwargs):\n",
    "    latent = kwargs['latent']\n",
    "    if len(latent.size()) == 1:\n",
    "        latent = latent.unsqueeze(0)\n",
    "    return model.decode(latent)\n",
    "\n",
    "def visualize_traverse(limit: tuple, spacing, data=None, test=False):\n",
    "    interp_values = torch.arange(limit[0], limit[1]+spacing, spacing)\n",
    "    num_cols = interp_values.size(0)\n",
    "\n",
    "    sample_images_dict, sample_labels_dict = prepare_data_for_visualization(next(iter(train_loader)))\n",
    "    encodings = dict()\n",
    "\n",
    "    for key in sample_images_dict.keys():\n",
    "        encodings[key], _  = encode_deterministic(images=sample_images_dict[key], labels=sample_labels_dict[key])\n",
    "\n",
    "    gifs = []\n",
    "    for key in encodings:\n",
    "        latent_orig = encodings[key]\n",
    "        label_orig = sample_labels_dict[key]\n",
    "        print('latent_orig: {}, label_orig: {}'.format(latent_orig, label_orig))\n",
    "        samples = []\n",
    "\n",
    "        # encode original on the first row\n",
    "        sample = decode_deterministic(latent=latent_orig, labels=label_orig)\n",
    "        for _ in interp_values:\n",
    "            samples.append(sample)\n",
    "        for zid in range(z_dim):\n",
    "            for val in interp_values:\n",
    "                latent = latent_orig\n",
    "                latent[:, zid] = val\n",
    "                set_z(latent, zid, val)\n",
    "                sample = decode_deterministic(latent=latent, labels=label_orig)\n",
    "\n",
    "                samples.append(sample)\n",
    "                gifs.append(sample)\n",
    "                    \n",
    "        samples = torch.cat(samples, dim=0).cpu()\n",
    "        samples = torchvision.utils.make_grid(samples, nrow=num_cols)\n",
    "        \n",
    "        file_name = os.path.join(\".\", '{}_{}.{}'.format(\"traverse\", key, \"png\"))\n",
    "        torchvision.utils.save_image(samples, file_name)\n",
    "        \n",
    "    total_rows = num_labels * l_dim + \\\n",
    "                 z_dim * int(traverse_z) + \\\n",
    "                 num_labels * int(traverse_c)\n",
    "    gifs = torch.cat(gifs)\n",
    "    gifs = gifs.view(len(encodings), total_rows, num_cols,\n",
    "                     num_channels, image_size, image_size).transpose(1, 2)\n",
    "    for i, key in enumerate(encodings.keys()):\n",
    "        for j, val in enumerate(interp_values):\n",
    "            file_name = \\\n",
    "                os.path.join('.', '{}_{}_{}.{}'.format('tmp', key, str(j).zfill(2), '.png'))\n",
    "            torchvision.utils.save_image(tensor=gifs[i][j].cpu(),\n",
    "                                         filename=file_name,\n",
    "                                         nrow=total_rows, pad_value=1)\n",
    "            \n",
    "        file_name = os.path.join('.', '{}_{}.{}'.format('traverse', key, 'gif'))\n",
    "\n",
    "        grid2gif(str(os.path.join('.', '{}_{}*.{}').format('tmp', key, 'png')),\n",
    "                 file_name, delay=10)\n",
    "\n",
    "        # Delete temp image files\n",
    "        for j, val in enumerate(interp_values):\n",
    "            os.remove(\n",
    "                os.path.join('.', '{}_{}_{}.{}'.format('tmp', key, str(j).zfill(2), '.png')))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_orig: tensor([[-0.0428, -0.0960,  0.0179, -1.3545,  1.4628,  1.5551,  0.7217, -0.6405]],\n",
      "       grad_fn=<SliceBackward>), label_orig: tensor([0])\n",
      "latent_orig: tensor([[ 0.0060, -0.0571,  0.0738,  1.2968,  0.0695, -0.4443, -0.0866, -1.1218]],\n",
      "       grad_fn=<SliceBackward>), label_orig: tensor([0])\n",
      "latent_orig: tensor([[-0.0310, -0.0670,  0.0620, -0.7422, -1.1748, -0.1942,  1.5837, -1.1176]],\n",
      "       grad_fn=<SliceBackward>), label_orig: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "min_ = -3\n",
    "max_ = 3\n",
    "spacing_ = 0.1\n",
    "samples = visualize_traverse(limit=(min_,max_), spacing=spacing_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
