{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from math import gamma\n",
    "\n",
    "def random_choice_full(input, n_samples, number_of_gausses):\n",
    "        from torch import multinomial, ones\n",
    "        if n_samples * number_of_gausses < input.shape[0]:\n",
    "            replacement = False\n",
    "        else:\n",
    "            replacement = True\n",
    "        idx = multinomial(ones(input.shape[0]), n_samples * number_of_gausses, replacement=replacement)\n",
    "        sampled = input[idx].reshape(number_of_gausses, n_samples, -1)\n",
    "#         return torch.mean(sampled, axis=1)\n",
    "        return sampled\n",
    "\n",
    "def provide_weights_for_x(x, how=None, device=None, n_samples=None, times=None):\n",
    "    dim = x.shape[1]\n",
    "    \n",
    "    if n_samples is None:\n",
    "        n_samples = dim\n",
    "    if times is None:\n",
    "        times = dim\n",
    "        \n",
    "    scale = (1 / dim)\n",
    "    sampled_points = random_choice_full(x, n_samples, times)\n",
    "\n",
    "    if how == \"gauss\":\n",
    "        from torch.distributions import MultivariateNormal\n",
    "        \n",
    "        cov_mat = (scale * torch.eye(dim)).repeat(dim, 1, 1)\n",
    "        mvn = MultivariateNormal(loc=sampled_points.to(device), covariance_matrix=cov_mat.to(device))\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "        \n",
    "    elif how == \"sqrt\":\n",
    "        weight_vector = torch.sqrt(1 + sampled_points.reshape(-1, 1, dim).to(device) ** 2) ** (-1)\n",
    "        \n",
    "    elif how == \"log\":\n",
    "        weight_vector = torch.log(1 + sampled_points.reshape(-1, 1, dim).to(device)**2)\n",
    "        \n",
    "    elif how == \"TStudent\":\n",
    "        from torch.distributions.studentT import StudentT\n",
    "        \n",
    "        mvn = StudentT(df=1, loc=x.mean(0), scale=scale)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "        # to trzeba poprawić ?!\n",
    "    elif how == \"Cauchy\":\n",
    "        from torch.distributions.cauchy import Cauchy\n",
    "        \n",
    "        mvn = Cauchy(loc=x.mean(0), scale=1)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "    elif how == \"Gumbel\":\n",
    "        from torch.distributions.gumbel import Gumbel\n",
    "        \n",
    "        mvn = Gumbel(loc=x.mean(0), scale=1)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "    elif how == \"Laplace\":\n",
    "        from torch.distributions.laplace import Laplace\n",
    "        \n",
    "        mvn = Laplace(loc=x.mean(0), scale=1)\n",
    "        weight_vector = torch.exp(mvn.log_prob(x.reshape(-1, 1, dim).to(device)))\n",
    "    return sampled_points, weight_vector\n",
    "    \n",
    "class WICA(object):\n",
    "    def __init__(self):\n",
    "        self.number_of_gausses = 10\n",
    "        self.z_dim = 5\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def wica_loss(self, z, latent_normalization=False, how=\"gauss\"):\n",
    "        z1 = z[:len(z)//2]\n",
    "        z2 = z[len(z)//2+1:]\n",
    "        if latent_normalization:\n",
    "            x1 = (z1 - z1.mean(dim=1, keepdim=True)) / z1.std(dim=1, keepdim=True)\n",
    "            x2 = (z2 - z2.mean(dim=1, keepdim=True)) / z2.std(dim=1, keepdim=True)\n",
    "        else:\n",
    "            x1 = z1\n",
    "            x2 = z2\n",
    "        dim = self.z_dim if self.z_dim is not None else x.shape[1]\n",
    "\n",
    "\n",
    "        _, weight_vector = provide_weights_for_x(\n",
    "                x=x1, \n",
    "                how=how,\n",
    "                device = self.device\n",
    "        )\n",
    "        \n",
    "        \n",
    "        sum_of_weights = torch.sum(weight_vector, axis=0)\n",
    "        \n",
    "        weight_sum = torch.sum(x2.reshape(1,x2.shape[0], x2.shape[1]) * weight_vector, axis=0)\n",
    "\n",
    "        weight_mean = weight_sum / sum_of_weights\n",
    "\n",
    "        xm = x2 - weight_mean\n",
    "        wxm = torch.sum(xm.reshape(1,xm.shape[0], xm.shape[1]) * weight_vector, axis=0)\n",
    "\n",
    "        wcov = (wxm.reshape(1 ,wxm.shape[0], wxm.shape[1]).permute(0, 2, 1).matmul(xm)) / sum_of_weights\n",
    "\n",
    "        diag = torch.diagonal(wcov ** 2, dim1=1, dim2=2)\n",
    "        diag_pow_plus = diag.reshape(diag.shape[0], diag.shape[1], -1) + diag.reshape(diag.shape[0], -1, diag.shape[1])\n",
    "\n",
    "        tmp = (2 * wcov ** 2 / diag_pow_plus)\n",
    "\n",
    "        triu = torch.triu(tmp, diagonal=1)\n",
    "        normalize = 2.0 / (dim * (dim - 1))\n",
    "        cost = torch.sum(normalize * triu) / self.number_of_gausses\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0011)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, weight_vector = provide_weights_for_x(t, 'sqrt')\n",
    "sum_of_weights = torch.sum(weight_vector, axis=0)\n",
    "\n",
    "weight_sum = torch.sum(t.reshape(1,t.shape[0], t.shape[1])*weight_vector, axis=0)\n",
    "weight_mean = weight_sum / sum_of_weights\n",
    "xm = t-weight_mean\n",
    "wxm = torch.sum(xm.reshape(1,xm.shape[0], xm.shape[1])*weight_vector, axis=0)\n",
    "\n",
    "wcov = (wxm.reshape(1 ,wxm.shape[0], wxm.shape[1]).permute(0, 2, 1).matmul(xm)) / sum_of_weights\n",
    "\n",
    "diag = torch.diagonal(wcov ** 2, dim1=1, dim2=2)\n",
    "diag_pow_plus = diag.reshape(diag.shape[0], diag.shape[1], -1) + diag.reshape(diag.shape[0], -1, diag.shape[1])\n",
    "\n",
    "tmp = (2 * wcov ** 2 / diag_pow_plus)\n",
    "triu = torch.triu(tmp, diagonal=1)\n",
    "normalize = 2.0 / (3 * (3 - 1))\n",
    "cost = torch.sum(normalize * triu) / 5\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0456,  0.0034, -0.0198, -0.0856])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wica = WICA()\n",
    "t = torch.sin(torch.randn(1200)).resize(300,4)\n",
    "torch.mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled_points: \n",
      " tensor([[[-0.6993, -0.2958,  0.4742, -0.9557]],\n",
      "\n",
      "        [[ 0.4507, -0.4991, -0.4388,  0.7413]],\n",
      "\n",
      "        [[ 0.6199, -0.7606, -0.9729, -0.0354]],\n",
      "\n",
      "        [[-0.8326, -0.8815,  0.3487,  0.9553]],\n",
      "\n",
      "        [[ 0.9945,  0.2977,  0.6661,  0.2242]]])\n",
      "weight_vector: \n",
      " tensor([[[0.3981, 0.0839, 0.2028, 0.6489]],\n",
      "\n",
      "        [[0.1849, 0.2224, 0.1761, 0.4379]],\n",
      "\n",
      "        [[0.3252, 0.4565, 0.6660, 0.0013]],\n",
      "\n",
      "        [[0.5267, 0.5749, 0.1148, 0.6484]],\n",
      "\n",
      "        [[0.6876, 0.0849, 0.3672, 0.0491]]])\n",
      "t: \n",
      " tensor([[-0.8650,  0.4725, -0.6094, -0.2222],\n",
      "        [-0.1985,  0.7913,  0.9632,  0.9873],\n",
      "        [-0.3821, -0.9996,  0.5813, -0.6832],\n",
      "        ...,\n",
      "        [-0.1775, -0.4542,  0.4860, -0.5693],\n",
      "        [ 0.6199, -0.7606, -0.9729, -0.0354],\n",
      "        [ 0.2646,  0.7916, -0.7701, -0.9893]])\n"
     ]
    }
   ],
   "source": [
    "dim = t.shape[1]\n",
    "\n",
    "sampled_points = random_choice_full(t, 1, 5)\n",
    "weight_vector = torch.log(1 + sampled_points.reshape(-1, 1, dim)**2)\n",
    "print(\"sampled_points: \\n\", sampled_points)\n",
    "print(\"weight_vector: \\n\", weight_vector)\n",
    "print(\"t: \\n\", t)\n",
    "# własciwa funkcja\n",
    "# weight_sum = t.T.matmul(weight_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4521)\n",
      "tensor(0.3177)\n",
      "tensor(1.4335)\n",
      "tensor(0.3557)\n",
      "tensor(0.5420)\n",
      "tensor(0.9022)\n",
      "tensor(0.7318)\n",
      "tensor(1.7655)\n",
      "tensor(1.2940)\n",
      "tensor(0.5641)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(1000*wica.wica_loss(t, latent_normalization=True, how=\"sqrt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 10, 2]' is invalid for input of size 1200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-406-3855917ea8fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# t.reshape(1,5,2).matmul(weight_vector)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 10, 2]' is invalid for input of size 1200"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,10,2)[0])\n",
    "print(weight_vector)\n",
    "\n",
    "t.reshape(1,10,2) * weight_vector\n",
    "# t.reshape(1,5,2).matmul(weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'sampled_points' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-315-0de896d29b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwica_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sqrt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-188-1c5e1a3855de>\u001b[0m in \u001b[0;36mwica_loss\u001b[0;34m(self, z, latent_normalization, how)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-188-1c5e1a3855de>\u001b[0m in \u001b[0;36mprovide_weights_for_x\u001b[0;34m(x, how, device)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmvn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLaplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mweight_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msampled_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mWICA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'sampled_points' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(wica.wica_loss(t, latent_normalization=True, how=\"sqrt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '/Users/andrzej/Personal/Projects/disentanglement-pytorch')\n",
    "from models.ae import AEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AEModel(\n",
       "  (encoder): SimpleConv64(\n",
       "    (main): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Flatten3D()\n",
       "      (13): Linear(in_features=256, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): SimpleConv64(\n",
       "    (main): Sequential(\n",
       "      (0): Unsqueeze3D()\n",
       "      (1): Conv2d(8, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (10): ReLU(inplace=True)\n",
       "      (11): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from architectures import encoders, decoders\n",
    "\n",
    "encoder_name = \"SimpleConv64\"\n",
    "decoder_name = \"SimpleConv64\"\n",
    "\n",
    "encoder = getattr(encoders, encoder_name)\n",
    "decoder = getattr(decoders, decoder_name)\n",
    "\n",
    "model = AEModel(encoder(8, 1, 64), decoder(8, 1, 64)).to(torch.device('cpu'))\n",
    "\n",
    "checkpoint = torch.load('/Users/andrzej/Personal/results/sqrt-wica-LR-1/last', map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(checkpoint['model_states']['G'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_loader import get_dataloader\n",
    "\n",
    "train_loader = get_dataloader('dsprites_full', '/Users/andrzej/Personal/Projects/data/test_dsets', 3,\n",
    "                              123, num_workers=1, pin_memory=True, image_size=64, \n",
    "                              include_labels=None, shuffle=True, droplast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "a,b = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils\n",
    "def visualize_recon(input_image, recon_image):\n",
    "        input_image = torchvision.utils.make_grid(input_image)\n",
    "        recon_image = torchvision.utils.make_grid(recon_image)\n",
    "\n",
    "        white_line = torch.ones((3, input_image.size(1), 10)).to('cpu')\n",
    "        samples = torch.cat([input_image, white_line, recon_image], dim=2)\n",
    "\n",
    "        torchvision.utils.save_image(samples, \"test.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_recon(x,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.utils import grid2gif, get_data_for_visualization, prepare_data_for_visualization\n",
    "import os\n",
    "\n",
    "z_dim = 8\n",
    "l_dim = 0\n",
    "traverse_z = True\n",
    "traverse_c = False\n",
    "num_labels = 0\n",
    "image_size = 64\n",
    "num_channels = train_loader.dataset.num_channels()\n",
    "\n",
    "def set_z(z, latent_id, val):\n",
    "    z[:, latent_id] += val\n",
    "\n",
    "def encode_deterministic(**kwargs):\n",
    "    images = kwargs['images']\n",
    "    if len(images.size()) == 3:\n",
    "        images = images.unsqueeze(0)\n",
    "    z = model.encode(images)\n",
    "    means = z.mean(dim=1, keepdim=True)\n",
    "    stds = z.std(dim=1, keepdim=True)\n",
    "    normalized_data = (z - means) / stds\n",
    "    return normalized_data\n",
    "\n",
    "def decode_deterministic(**kwargs):\n",
    "    latent = kwargs['latent']\n",
    "    if len(latent.size()) == 1:\n",
    "        latent = latent.unsqueeze(0)\n",
    "    return model.decode(latent)\n",
    "\n",
    "def visualize_traverse(limit: tuple, spacing, data=None, test=False):\n",
    "    interp_values = torch.arange(limit[0], limit[1]+spacing, spacing)\n",
    "    num_cols = interp_values.size(0)\n",
    "\n",
    "    sample_images_dict, sample_labels_dict = prepare_data_for_visualization(next(iter(train_loader)))\n",
    "    encodings = dict()\n",
    "        \n",
    "    for key in sample_images_dict.keys():\n",
    "        encodings[key] = encode_deterministic(images=sample_images_dict[key], labels=sample_labels_dict[key])\n",
    "\n",
    "    gifs = []\n",
    "    for key in encodings:\n",
    "        latent_orig = encodings[key]\n",
    "        label_orig = sample_labels_dict[key]\n",
    "        print('latent_orig: {}, label_orig: {}'.format(latent_orig, label_orig))\n",
    "        samples = []\n",
    "\n",
    "        # encode original on the first row\n",
    "        sample = decode_deterministic(latent=latent_orig.detach(), labels=label_orig)\n",
    "        for _ in interp_values:\n",
    "            samples.append(sample)\n",
    "        for zid in range(z_dim):\n",
    "            for val in interp_values:\n",
    "                latent = latent_orig.clone()\n",
    "                latent[:, zid] += val\n",
    "                set_z(latent, zid, val)\n",
    "                sample = decode_deterministic(latent=latent, labels=label_orig)\n",
    "\n",
    "                samples.append(sample)\n",
    "                gifs.append(sample)\n",
    "                    \n",
    "        samples = torch.cat(samples, dim=0).cpu()\n",
    "        samples = torchvision.utils.make_grid(samples, nrow=num_cols)\n",
    "        \n",
    "        file_name = os.path.join(\".\", '{}_{}.{}'.format(\"traverse\", key, \"png\"))\n",
    "        torchvision.utils.save_image(samples, file_name)\n",
    "        \n",
    "    total_rows = num_labels * l_dim + \\\n",
    "                 z_dim * int(traverse_z) + \\\n",
    "                 num_labels * int(traverse_c)\n",
    "    gifs = torch.cat(gifs)\n",
    "    gifs = gifs.view(len(encodings), total_rows, num_cols,\n",
    "                     num_channels, image_size, image_size).transpose(1, 2)\n",
    "    for i, key in enumerate(encodings.keys()):\n",
    "        for j, val in enumerate(interp_values):\n",
    "            file_name = \\\n",
    "                os.path.join('.', '{}_{}_{}.{}'.format('tmp', key, str(j).zfill(2), '.png'))\n",
    "            torchvision.utils.save_image(tensor=gifs[i][j].cpu(),\n",
    "                                         filename=file_name,\n",
    "                                         nrow=total_rows, pad_value=1)\n",
    "            \n",
    "        file_name = os.path.join('.', '{}_{}.{}'.format('traverse', key, 'gif'))\n",
    "\n",
    "        grid2gif(str(os.path.join('.', '{}_{}*.{}').format('tmp', key, 'png')),\n",
    "                 file_name, delay=10)\n",
    "\n",
    "        # Delete temp image files\n",
    "        for j, val in enumerate(interp_values):\n",
    "            os.remove(\n",
    "                os.path.join('.', '{}_{}_{}.{}'.format('tmp', key, str(j).zfill(2), '.png')))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_orig: tensor([[-0.3528,  0.5078,  1.3924, -0.6429,  0.6594,  0.3798, -0.0238, -1.9199]],\n",
      "       grad_fn=<DivBackward0>), label_orig: tensor([0])\n",
      "latent_orig: tensor([[-0.3525,  1.4628,  1.0065,  0.0366,  0.8083, -1.1181, -1.1652, -0.6785]],\n",
      "       grad_fn=<DivBackward0>), label_orig: tensor([0])\n",
      "latent_orig: tensor([[ 0.1863,  1.0236, -1.0211, -1.2042, -0.2146,  1.0300,  1.1719, -0.9719]],\n",
      "       grad_fn=<DivBackward0>), label_orig: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "min_ = -3\n",
    "max_ = 3\n",
    "spacing_ = 0.2\n",
    "samples = visualize_traverse(limit=(min_,max_), spacing=spacing_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
